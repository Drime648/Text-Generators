{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text generation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyjQo8ucDryVYZyT7VQZu+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drime648/Text-Generators/blob/main/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThqIG6nQk-QD"
      },
      "source": [
        "#Play Generator with RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwQinbgBlCXs"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QO2_WNKnFRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc07511-922b-4bf7-cf6d-9427d90fe17d"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImfElyurnf8a"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "kQWxqmJjn--q",
        "outputId": "39671d1a-341f-4433-daa8-acdf6b65421f"
      },
      "source": [
        "text[:250]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1fhJZmIoA4J"
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN9QNABioYZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bebe70-6c97-466f-bbf2-a9628a4d364f"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tamq9HW-hZcn"
      },
      "source": [
        "##Preprocess functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu4qEYxlobxa"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "#chars to numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYzSFVmTgoxd"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "#numbers to chars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG9MXarmgvMs"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "#numbers to a full string of many chars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q7Sq26PhX_y"
      },
      "source": [
        "## Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHzF5yeshdGz",
        "outputId": "360f78b1-18b4-4921-eac6-7b8a073a61f1"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ENP8CsWhezr"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyGijcifhjKK",
        "outputId": "82936a8e-41a5-49ef-d27b-46235ff521d8"
      },
      "source": [
        "for ids in ids_dataset.take(21):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n",
            "z\n",
            "e\n",
            "n\n",
            ":\n",
            "\n",
            "\n",
            "B\n",
            "e\n",
            "f\n",
            "o\n",
            "r\n",
            "e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEP7ZRmJhmxr"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "#input will be \"hell\", output will be \"ello\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbMeHH6thu07",
        "outputId": "b8bfd6fc-738f-4a9d-e899-3f3ba738c4ff"
      },
      "source": [
        "examples_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM7K0RYFh0TL",
        "outputId": "ee8883bd-3d2e-4f07-a6d9-ece97db984c3"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQJwzeLSj4Pe",
        "outputId": "cf07772e-cf48-4489-e891-5f5f94c55274"
      },
      "source": [
        "for seq in sequences.take(1):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN4q7b6Ym-l_"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLSSoOCPnk4L",
        "outputId": "5ce1bf3f-48e4-4078-eba2-843eb27a34e3"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ESgb5monrUL"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94rzpZ4XrE8P",
        "outputId": "1f04679d-9079-4a00-fbee-33a62516df2a"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())\n",
        "\n",
        "    #inpu = 'f' output = 'i'\n",
        "    # f->i, i->r, r->s..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pbk-JsqrHZM",
        "outputId": "ac30da53-3921-4199-c820-225b5d6b3749"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_6Rar5areer"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoBwLNact5Ex"
      },
      "source": [
        "##Make Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4RRIV72rhds"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo2i0umcrz1c"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YluSFte9sYGI",
        "outputId": "f385fd0b-4f99-42a3-8800-4cf597f5cf53"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\", input_example_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size) (64, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVsUVrofsVa8",
        "outputId": "c64e566a-0129-4419-9fdd-5192d994c743"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  16896     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  67650     \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8af58QtsV5M"
      },
      "source": [
        "model.compile(loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer = 'adam',\n",
        "              metrics = [\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rPh_WPgtoX8"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    save_best_only = True,\n",
        "    monitor = \"accuracy\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF79qr5xtrRM",
        "outputId": "20ad4ef8-d4fe-476b-f784-7577f7e2f0e5"
      },
      "source": [
        "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 2.7181 - accuracy: 0.2757\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.9839 - accuracy: 0.4196\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.7017 - accuracy: 0.4949\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.5412 - accuracy: 0.5370\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.4442 - accuracy: 0.5622\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3760 - accuracy: 0.5788\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3253 - accuracy: 0.5917\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2799 - accuracy: 0.6034\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.2389 - accuracy: 0.6138\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.1996 - accuracy: 0.6240\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.1593 - accuracy: 0.6354\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1185 - accuracy: 0.6466\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.0748 - accuracy: 0.6595\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.0291 - accuracy: 0.6733\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 0.9809 - accuracy: 0.6883\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 0.9297 - accuracy: 0.7045\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8774 - accuracy: 0.7212\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8255 - accuracy: 0.7384\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.7752 - accuracy: 0.7545\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7277 - accuracy: 0.7699\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 0.6821 - accuracy: 0.7848\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 0.6440 - accuracy: 0.7967\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 11s 60ms/step - loss: 0.6098 - accuracy: 0.8072\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 0.5786 - accuracy: 0.8170\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.5555 - accuracy: 0.8236\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.5348 - accuracy: 0.8298\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.5139 - accuracy: 0.8356\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.4988 - accuracy: 0.8403\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.4858 - accuracy: 0.8438\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 11s 60ms/step - loss: 0.4753 - accuracy: 0.8464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdAsqPHI1p_g"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ilxIrC1vp8"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS8l280v1zOM",
        "outputId": "d29f606a-8ba8-452a-eac6-9dd624c0e098"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Good mother, be it that signs of war Tantens\n",
            "He he hath kept a misder's voice:\n",
            "Yet I have known to come against yourself.\n",
            "I'll tell thee what else were sinning.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "\n",
            "ANGELO:\n",
            "\n",
            "Nather:\n",
            "Beseech you, sir, in Yorksay,\n",
            "People till I all the untimely falls.\n",
            "\n",
            "Nurse:\n",
            "Now, afore God, Itaby; be good to curse\n",
            "Against him from the titty time of mine?\n",
            "\n",
            "ROMEO:\n",
            "And breadhe with the that word, indeed, had covether not\n",
            "the greatest twenty Bolingbroke?\n",
            "\n",
            "GLOUCESTER:\n",
            "What friar is it to fear. What dog that I may save you, nurse.\n",
            "\n",
            "Nurse:\n",
            "ay, but given it your daughter bids your love:\n",
            "My lords, be not use to slay that feast.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Strong, and I am too good for me:\n",
            "That is for the man in post haste\n",
            "good dangers of smile creat? O truth, God grants\n",
            "In more than one o' the face to show Lichmond?\n",
            "For God is gone, it is the labie and these,\n",
            "Whereof I should speak, or do I see three sun\n",
            "And stand on me less Kate Katharina,\n",
            "Compusain our substancies to his father's soldier,\n",
            "The high will  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.745391607284546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtnAzClmt7lV"
      },
      "source": [
        "#Seq to Seq text translator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LotXbzhIt_0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb305b8c-0750-40ca-a508-40abefbc2e69"
      },
      "source": [
        "!pip install tensorflow_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/ed/bbb51e9eccca0c2bfdf9df66e54cdff563b6f32daed9255da9b9a541368f/tensorflow_text-2.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (1.34.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.8.0->tensorflow_text) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.31.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow_text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnetTiICDt2g"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJyBfaPDyKb"
      },
      "source": [
        "use_builtins = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkolSYYJD_aM"
      },
      "source": [
        "##Shape Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR7W1jYCD3I8"
      },
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WRfyrs5EDc7"
      },
      "source": [
        "##Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBLZfQDZEELb",
        "outputId": "c950c9b5-baf7-4d9f-d026-d302b1dcf3e6"
      },
      "source": [
        "# Download the file\n",
        "import pathlib\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS7Btz0bERqL"
      },
      "source": [
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  inp = [inp for targ, inp in pairs]\n",
        "  targ = [targ for targ, inp in pairs]\n",
        "\n",
        "  return targ, inp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbpr6Yf8EWjb",
        "outputId": "64299cbd-440d-4b67-a4cd-6399ec60ba09"
      },
      "source": [
        "targ, inp = load_data(path_to_file)\n",
        "print(inp[-1])\n",
        "print(targ[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA2pQFyEEZiL",
        "outputId": "6182eccc-20fd-4071-8700-1bacb631ab22"
      },
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).batch(BATCH_SIZE).shuffle(BUFFER_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "dataset\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMA9fqscdgqu",
        "outputId": "36c1a212-38d4-427e-a968-9353c220a5e2"
      },
      "source": [
        "val_size = int(0.3 * len(dataset))\n",
        "val_dataset = dataset.take(val_size).prefetch(tf.data.AUTOTUNE)\n",
        "train_dataset = dataset.skip(val_size).prefetch(tf.data.AUTOTUNE)\n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.string)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLnvSerrErJ7",
        "outputId": "3e7bd01e-04b4-496d-a319-dd9fe91bfc68"
      },
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'No puedo hablar sobre nada con Tom.'\n",
            " b'No puedo recordar su nombre ahora mismo.'\n",
            " b'No puedo entender por qu\\xc3\\xa9 \\xc3\\xa9l hizo eso.'\n",
            " b'Llev\\xc3\\xa9 a la espalda la bolsa pesada.'\n",
            " b'Atrap\\xc3\\xa9 a Tom coqueteando con mi esposa.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b\"I can't talk to Tom about anything.\"\n",
            " b\"I can't think of his name just now.\"\n",
            " b\"I can't understand why he did that.\"\n",
            " b'I carried the heavy bag on my back.'\n",
            " b'I caught Tom flirting with my wife.'], shape=(5,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYisb2z-F8W4",
        "outputId": "777641a8-f89e-414f-ed64-5e322c4553b7"
      },
      "source": [
        "example_text = tf.constant('¿Todavía está en casa?')\n",
        "\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
            "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p2yYXRXE5Zc"
      },
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GzuMElgF0wM",
        "outputId": "e26bab3b-e5d4-4958-c54b-4e17c72b1f4f"
      },
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "¿Todavía está en casa?\n",
            "[START] ¿ todavia esta en casa ? [END]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iipq5OqlJBnj"
      },
      "source": [
        "###Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiT48dWzJC5M"
      },
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = preprocessing.TextVectorization(\n",
        "    max_tokens=max_vocab_size,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7-Pa1kPKZEM",
        "outputId": "bb5a8952-9480-4010-becf-33cf47b1e0ea"
      },
      "source": [
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'de', 'que', 'a', 'no', 'tom', 'la', 'el', 'en']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m11L4nemKb0L",
        "outputId": "46375839-c520-4d5a-93d7-b3b35cadc3a9"
      },
      "source": [
        "output_text_processor = preprocessing.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHZkPMKlLjlM",
        "outputId": "7e8dfd35-2885-4aed-c091-a2704fa58144"
      },
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 13), dtype=int64, numpy=\n",
              "array([[   5,   64,   91,  136,   65,   22,    6,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   64, 1052,   17,  236,   87,  161,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   64,  581,   16,   33,   42,  123,   38,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [3546,    4,    7, 1305,    7, 1100, 2820,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   1,    4,    6,    1,   22,   20,  452,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   1,    3,    9,  545,    5,   12, 2170,    6,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   1,    3,   20,  236,    5,   10,    6,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   1,    3,    9,  545,   20,  236,    5,   10,    6,    0,    0,\n",
              "           0,    0],\n",
              "       [  24,    1,   16,   17,    1,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  298,  506,    2,    1,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   2,  209,  262,  329,   71,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   13,   12,  295, 2167,  201,  199,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  533,  803,    3,    1,    2,  440,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [ 326,   54,   14,    3,    6,   12,   86,    3,  900,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  645,    3,  204,   59,  272,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [  14,  326,  436,   51,   12,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [  14,  326,   41, 1497,    3,   12,  355,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  178,    3,  204,  606,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  178,    3, 3831,  459,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  178,  186,  339,    8,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  178,    3, 1269,    2,  129,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [ 183,    2,   38,    5, 2335,    4, 1103,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   12,  617,  270,    2,    3,    8, 4273,   13,   99,  647,\n",
              "           9,  909],\n",
              "       [   5,   12,    1,  270,    2,    3, 1269,  651,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,    1,    9,   27, 4495, 2576,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   24,  617, 1461,   31,  415,  317,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   85,    3,   23,  524,    9,   49,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   44, 4850,   39, 3589,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [  32,    5,   96, 2928,   27, 2979,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   85,    3, 3309,    2,  156,   38,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5, 3594,    4,    6,   16,   17,  664,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   12,  304,   72,   27,  576,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   12,  424,   47,   12,    1,  134,    5,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   12,  424,   22,  193,  524,  389,    6,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [ 216,  574,   76,  186,   21,    6,   87,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   44,  109,    4,    6,   80,   30,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [ 683,   44,  373,    4,  458,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   44,  373,    4,  458,   80,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   29,   44,  109,   80,   30,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,  287,    3,  997,   20,  220,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5, 3622,    4,   20,  142,    9,    7,   81,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [  39,  128,    5,   45,  456,    2,  558, 1883,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   45,  429,  100,    3,  271,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   65,  136,    8,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   65,    2, 1933,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   35,  211,    2,  193,   10,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,    7,  383,  216,   44,    1,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   47,    6,   21,    4, 1487,  134,    5,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   47,  753,   39,  128,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   47,  553,  199,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,    3, 1732,  135,  160,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,  989,  257,    8,    1, 1173,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   33,   50,    2,  715,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   33, 2158,    2,  138,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,  638,   13, 3433,    6,   28,  116,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,  638, 4841,    6,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,  638,  753,   42,  176,   69,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,    4,  193, 1110,  554,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,  193,   57, 1072,   39,  256,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,  193,  924,   39,  256,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   45,  212,   16,   33,    6,   21,   59, 1319,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   76,   16,   33,   13,   95, 2478,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   12,   58,  521,    2,  463, 4364,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   5,   12,   58,  313,    9,    8, 1049,    0,    0,    0,    0,\n",
              "           0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyO1AcgoO5cr",
        "outputId": "4eae9670-53e2-4023-b3ce-53810538ffa5"
      },
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'no puedo hablar sobre nada con tom      '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj7y1GOWPiDs"
      },
      "source": [
        "###Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhUtgvXrPjHs"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiq0ulHQPjr8"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqn8Bip5Pr6c",
        "outputId": "d43a6d03-e43c-4d66-8642-e731ed8899d9"
      },
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input batch, shape (batch): (64,)\n",
            "Input batch tokens, shape (batch, s): (64, 13)\n",
            "Encoder output, shape (batch, s, units): (64, 13, 1024)\n",
            "Encoder state, shape (batch, units): (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu4pxLX7UCDR"
      },
      "source": [
        "##Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDpzCRl1Qszs"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj9fEsltT38v"
      },
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ75DOAtT6ht",
        "outputId": "ebc79620-0be8-4004-f792-8dc16b84718b"
      },
      "source": [
        "(example_tokens != 0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irhzzvXyUK6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11426d8c-abc6-48d7-d7ac-f489644b2c65"
      },
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIyeDexedn9A",
        "outputId": "5c2608e2-0be3-48d1-a646-4e69c524a4b6"
      },
      "source": [
        "attention_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 2, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO6gpPvQdMy4"
      },
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "-aFsycdnd1vL",
        "outputId": "67e97c94-8e1b-4947-bbbd-d35d1eb14c9c"
      },
      "source": [
        "plt.suptitle('Attention weights for one sequence')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "a1 = plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "# freeze the xlim\n",
        "plt.xlim(plt.xlim())\n",
        "plt.xlabel('Attention weights')\n",
        "\n",
        "a2 = plt.subplot(1, 2, 2)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "plt.xlabel('Attention weights, zoomed')\n",
        "\n",
        "# zoom in\n",
        "top = max(a1.get_ylim())\n",
        "zoom = 0.85*top\n",
        "a2.set_ylim([0.90*top, top])\n",
        "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1ffd16bc90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izo9L96deEi8"
      },
      "source": [
        "###Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAHd6i3QeFdq"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCJ3BNDFfncL"
      },
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf04pgo-gR5r"
      },
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVLHiRWImURP"
      },
      "source": [
        "Decoder.call = call"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIpD6XPNmc0Y"
      },
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RzNWbS4mdQV"
      },
      "source": [
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor._index_lookup_layer('[START]').numpy()\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDGelRBFm96m",
        "outputId": "fa4b24d1-2de7-45fa-bc6a-bd5bd9a23b9e"
      },
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (64, 1, 5000)\n",
            "state shape: (batch_size, dec_units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG8DN_35nBvk"
      },
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPCRAekknVCE",
        "outputId": "9c3c724d-40de-489d-d54d-37d13a10449b"
      },
      "source": [
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['brakes'],\n",
              "       ['searched'],\n",
              "       ['put'],\n",
              "       ['pink'],\n",
              "       ['fashion']], dtype='<U16')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdnSWppFnWfX"
      },
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6og1bx1xna1V",
        "outputId": "8abb6772-8306-43fd-8842-c362aabf037a"
      },
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['tea'],\n",
              "       ['letter'],\n",
              "       ['resulted'],\n",
              "       ['lesson'],\n",
              "       ['someones']], dtype='<U16')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plhvLxpsnlsl"
      },
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxkDLOQnn9rV"
      },
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQUjOhzyn_tW"
      },
      "source": [
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkKkScw5oEmG"
      },
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzcCwEeIoFgF"
      },
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target the target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dJoq18LtuAG"
      },
      "source": [
        "TrainTranslator._train_step = _train_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byxw1vH1uv4m"
      },
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByMoWO2Eu7gU"
      },
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6GfFiOau8v1"
      },
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59qPj3glu_3V",
        "outputId": "d065a633-6284-44aa-be71-d58756882e2f"
      },
      "source": [
        "np.log(output_text_processor.vocabulary_size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.517193191416238"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvcH3PJPvBHl",
        "outputId": "577d8f97-bd1a-4dda-8887-e405a5b24502"
      },
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.712499>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.6678705>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5895367>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.382438>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.711454>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.782163>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.981436>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.674294>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.386696>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.3113718>}\n",
            "\n",
            "CPU times: user 4.18 s, sys: 130 ms, total: 4.31 s\n",
            "Wall time: 4.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE0ukAcWvC1E"
      },
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcjAgqKvMQ1"
      },
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahesDksPvNSk"
      },
      "source": [
        "translator.use_tf_function = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGpQJnBPvOV0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}